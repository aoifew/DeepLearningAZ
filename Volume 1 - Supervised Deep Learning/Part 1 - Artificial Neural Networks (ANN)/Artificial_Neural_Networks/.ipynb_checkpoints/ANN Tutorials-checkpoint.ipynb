{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ..., \n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 2, 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 0, 'Female', ..., 1, 0, 113931.57],\n",
       "       ..., \n",
       "       [709, 0, 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 1, 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 0, 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#Country - convert categories into numbers\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
       "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
       "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
       "       ..., \n",
       "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
       "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
       "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gender\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variables\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "#Drop first column - Dummy variable trap?\n",
    "#Each category maps to pair of values\n",
    "#France - 0.0, 0\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   6.19000000e+02, ...,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.01348880e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   6.08000000e+02, ...,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.12542580e+05],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   5.02000000e+02, ...,\n",
       "          1.00000000e+00,   0.00000000e+00,   1.13931570e+05],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.09000000e+02, ...,\n",
       "          0.00000000e+00,   1.00000000e+00,   4.20855800e+04],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   7.72000000e+02, ...,\n",
       "          1.00000000e+00,   0.00000000e+00,   9.28885200e+04],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.92000000e+02, ...,\n",
       "          1.00000000e+00,   0.00000000e+00,   3.81907800e+04]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n",
       "        -1.03227043,  1.10643166],\n",
       "       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n",
       "         0.9687384 , -0.74866447],\n",
       "       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n",
       "        -1.03227043,  1.48533467],\n",
       "       ..., \n",
       "       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n",
       "        -1.03227043,  1.41231994],\n",
       "       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n",
       "         0.9687384 ,  0.84432121],\n",
       "       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n",
       "        -1.03227043,  0.32472465]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.75486502, -0.57369368, -0.55204276, ...,  0.64259497,\n",
       "         0.9687384 ,  1.61085707],\n",
       "       [-0.5698444 , -0.57369368, -1.31490297, ...,  0.64259497,\n",
       "        -1.03227043,  0.49587037],\n",
       "       [-0.5698444 ,  1.74309049,  0.57162971, ...,  0.64259497,\n",
       "         0.9687384 , -0.42478674],\n",
       "       ..., \n",
       "       [-0.5698444 ,  1.74309049, -0.74791227, ...,  0.64259497,\n",
       "        -1.03227043,  0.71888467],\n",
       "       [ 1.75486502, -0.57369368, -0.00566991, ...,  0.64259497,\n",
       "         0.9687384 , -1.54507805],\n",
       "       [ 1.75486502, -0.57369368, -0.79945688, ...,  0.64259497,\n",
       "        -1.03227043,  1.61255917]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "# 11 - number of input dimensions - 11 columns\n",
    "# 6 - 11+1/2 - number of hidden layers, 1 indicates binary outcome\n",
    "# kernel_initializer - initialises the weights randomly and to be small numbers\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "#Sigmoid used to get probabilities as our output\n",
    "#Can then use these to \"rank\" the customers in order of probability to leave\n",
    "#Softmax used for >1 output\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "#optimizer - algorithm used to find optimal weights, adam = SGD\n",
    "#loss - loss function within SGD algorithm. Need to optimize to find optimal weights\n",
    "# binary_crossentropy - our outputs are binary\n",
    "#metrics - expects a list\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4880 - acc: 0.7961     \n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4271 - acc: 0.7960     \n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4221 - acc: 0.7960     \n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4188 - acc: 0.8171     \n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4166 - acc: 0.8249     \n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4150 - acc: 0.8270     \n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4132 - acc: 0.8307     \n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4121 - acc: 0.8314     \n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4104 - acc: 0.8319     \n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4103 - acc: 0.8342     \n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4096 - acc: 0.8344     \n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4089 - acc: 0.8340     \n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4081 - acc: 0.8332     \n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4073 - acc: 0.8347     \n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4069 - acc: 0.8335     \n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4067 - acc: 0.8354     \n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4063 - acc: 0.8360     \n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4055 - acc: 0.8354     \n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4054 - acc: 0.8351     \n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4052 - acc: 0.8349     \n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4045 - acc: 0.8344     \n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4043 - acc: 0.8346     \n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4044 - acc: 0.8345     \n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4039 - acc: 0.8364     \n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4040 - acc: 0.8369     \n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4033 - acc: 0.8350     \n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4029 - acc: 0.8366     \n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4029 - acc: 0.8367     \n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4030 - acc: 0.8345     \n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4027 - acc: 0.8361     \n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4023 - acc: 0.8362     \n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4025 - acc: 0.8371     \n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4023 - acc: 0.8361     \n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4023 - acc: 0.8361     \n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4018 - acc: 0.8364     \n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4019 - acc: 0.8365     \n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4020 - acc: 0.8349     \n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4020 - acc: 0.8344     \n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4019 - acc: 0.8354     \n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4016 - acc: 0.8349     \n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4018 - acc: 0.8349     \n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4018 - acc: 0.8367     \n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4015 - acc: 0.8359     \n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4017 - acc: 0.8349     \n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4016 - acc: 0.8369     \n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4012 - acc: 0.8355     \n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4013 - acc: 0.8371     \n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4014 - acc: 0.8346     \n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4007 - acc: 0.8349     \n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4013 - acc: 0.8357     \n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4011 - acc: 0.8342     \n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4009 - acc: 0.8341     \n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4009 - acc: 0.8365     \n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4007 - acc: 0.8362     \n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4006 - acc: 0.8350     \n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4008 - acc: 0.8345     \n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4007 - acc: 0.8355     \n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4003 - acc: 0.8339     \n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4004 - acc: 0.8359     \n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.4004 - acc: 0.8356     \n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3997 - acc: 0.8364     \n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3997 - acc: 0.8359     \n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3993 - acc: 0.8360     \n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3989 - acc: 0.8354     \n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3987 - acc: 0.8367     \n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3989 - acc: 0.8364     \n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3984 - acc: 0.8360     \n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3984 - acc: 0.8352     \n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3979 - acc: 0.8372     \n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3975 - acc: 0.8369     \n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3977 - acc: 0.8356     \n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3974 - acc: 0.8355     \n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3965 - acc: 0.8361     \n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3965 - acc: 0.8382     \n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3959 - acc: 0.8356     \n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3960 - acc: 0.8376     \n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3953 - acc: 0.8367     \n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3960 - acc: 0.8375     \n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3955 - acc: 0.8360     \n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3953 - acc: 0.8371     \n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3955 - acc: 0.8355     \n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3951 - acc: 0.8362     \n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3949 - acc: 0.8360     \n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3948 - acc: 0.8365     \n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3941 - acc: 0.8354     \n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3945 - acc: 0.8360     \n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s - loss: 0.3941 - acc: 0.8366     \n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3936 - acc: 0.8365     \n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3937 - acc: 0.8372     \n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3938 - acc: 0.8366     \n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3931 - acc: 0.8391     \n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3937 - acc: 0.8364     \n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3931 - acc: 0.8381     \n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3933 - acc: 0.8375     \n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3932 - acc: 0.8376     \n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3930 - acc: 0.8379     \n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3930 - acc: 0.8372     \n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3928 - acc: 0.8377     \n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3929 - acc: 0.8357     \n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s - loss: 0.3930 - acc: 0.8360     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c233f5898>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "#update weights either after each observation or after a batch\n",
    "#batch size = 10 updates weights after each 10 observations\n",
    "\n",
    "#epoch - every observation has passed through the classifier once\n",
    "#100 epochs\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21351111],\n",
       "       [ 0.29432389],\n",
       "       [ 0.14588986],\n",
       "       ..., \n",
       "       [ 0.16272601],\n",
       "       [ 0.12282191],\n",
       "       [ 0.18370497]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert probabilities into the predicted result of 1/0\n",
    "#if y_pred > 0.5 - true, else - false\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ..., \n",
       "       [False],\n",
       "       [False],\n",
       "       [False]], dtype=bool)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1537,   58],\n",
       "       [ 261,  144]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (1537+144)/2000\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
    "\n",
    "- Geography: France\n",
    "- Credit Score: 600\n",
    "- Gender: Male\n",
    "- Age: 40 years old\n",
    "- Tenure: 3 years\n",
    "- Balance: \\$60000\n",
    "- Number of Products: 2\n",
    "- Does this customer have a credit card ? Yes\n",
    "- Is this customer an Active Member: Yes\n",
    "- Estimated Salary: \\$50000\n",
    "\n",
    "\n",
    "So should we say goodbye to that customer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Data\n",
    "#Observation needs to be in horizontal not vertical vector\n",
    "#our data is in rows - not columns\n",
    "\n",
    "#France corresponds to pair of dummy variables 0 and 0\n",
    "#First 0 is entered as 0.0 to supress warnings when scaling integers in the next cell\n",
    "new_data = np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 , -0.57369368, -0.52111599,  0.91601335,  0.10961719,\n",
       "        -0.68538967, -0.2569057 ,  0.8095029 ,  0.64259497,  0.9687384 ,\n",
       "        -0.87203322]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transform\n",
    "new_data = sc.transform(new_data)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09444336]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = classifier.predict(new_data)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]], dtype=bool)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = (new_pred > 0.5)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#Use wrappers to use k-fold cross validation from sklearn with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the classifier using kfold cross validation\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4893 - acc: 0.7936     \n",
      "6400/7200 [=========================>....] - ETA: 0s - loss: 0.4982 - acc: 0.7934Epoch 2/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4835 - acc: 0.7974     \n",
      "7200/7200 [==============================] - 5s - loss: 0.4854 - acc: 0.7965     Epoch 2/100\n",
      "\n",
      "7090/7200 [============================>.] - ETA: 0s - loss: 0.4883 - acc: 0.7945Epoch 2/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4864 - acc: 0.7968     \n",
      "6690/7200 [==========================>...] - ETA: 0s - loss: 0.4952 - acc: 0.7934Epoch 2/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4869 - acc: 0.7943     \n",
      "Epoch 2/100\n",
      "6880/7200 [===========================>..] - ETA: 0s - loss: 0.4916 - acc: 0.7946\n",
      " 270/7200 [>.............................] - ETA: 4s - loss: 0.5237 - acc: 0.7852Epoch 2/100\n",
      " 410/7200 [>.............................] - ETA: 3s - loss: 0.5092 - acc: 0.7829\n",
      " 260/7200 [>.............................] - ETA: 2s - loss: 0.5159 - acc: 0.7808Epoch 2/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4840 - acc: 0.7969     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4333 - acc: 0.7937     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4302 - acc: 0.7969     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4274 - acc: 0.7975     \n",
      "\n",
      "Epoch 3/100\n",
      "Epoch 3/100\n",
      "6840/7200 [===========================>..] - ETA: 0s - loss: 0.4285 - acc: 0.7977\n",
      "Epoch 3/100\n",
      "  10/7200 [..............................] - ETA: 55s - loss: 0.3962 - acc: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.127263). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10/7200 [..............................] - ETA: 23s - loss: 0.5090 - acc: 0.7000\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4287 - acc: 0.7971     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4283 - acc: 0.7962     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4258 - acc: 0.7969     \n",
      "Epoch 4/100\n",
      "6170/7200 [========================>.....] - ETA: 0s - loss: 0.4240 - acc: 0.7945\n",
      "Epoch 4/100\n",
      "6390/7200 [=========================>....] - ETA: 0s - loss: 0.4222 - acc: 0.7956\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4222 - acc: 0.7975     \n",
      "7200/7200 [==============================] - 5s - loss: 0.4242 - acc: 0.7967     Epoch 4/100\n",
      "6620/7200 [==========================>...] - ETA: 0s - loss: 0.4197 - acc: 0.7976\n",
      "Epoch 4/100\n",
      "6690/7200 [==========================>...] - ETA: 0s - loss: 0.4205 - acc: 0.7975\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4244 - acc: 0.7956     \n",
      "Epoch 4/100\n",
      " 420/7200 [>.............................] - ETA: 5s - loss: 0.3980 - acc: 0.8095\n",
      "Epoch 4/100\n",
      "6680/7200 [==========================>...] - ETA: 0s - loss: 0.4171 - acc: 0.8127\n",
      "6550/7200 [==========================>...] - ETA: 0s - loss: 0.4207 - acc: 0.8134Epoch 5/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4221 - acc: 0.8079     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4243 - acc: 0.8094     \n",
      "Epoch 5/100\n",
      "7180/7200 [============================>.] - ETA: 0s - loss: 0.4184 - acc: 0.8124\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4184 - acc: 0.8122     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4206 - acc: 0.8042     \n",
      "Epoch 5/100\n",
      " 610/7200 [=>............................] - ETA: 5s - loss: 0.4216 - acc: 0.8082\n",
      " 300/7200 [>.............................] - ETA: 3s - loss: 0.3915 - acc: 0.8267Epoch 5/100\n",
      "1040/7200 [===>..........................] - ETA: 5s - loss: 0.4080 - acc: 0.8221\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4185 - acc: 0.8200     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4190 - acc: 0.8225     \n",
      "Epoch 6/100\n",
      "6960/7200 [============================>.] - ETA: 0s - loss: 0.4178 - acc: 0.8226\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4156 - acc: 0.8256     \n",
      "6880/7200 [===========================>..] - ETA: 0s - loss: 0.4210 - acc: 0.8225Epoch 6/100\n",
      "7140/7200 [============================>.] - ETA: 0s - loss: 0.4179 - acc: 0.8223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.128130). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50/7200 [..............................] - ETA: 9s - loss: 0.5583 - acc: 0.7800\n",
      " 130/7200 [..............................] - ETA: 10s - loss: 0.5277 - acc: 0.7462Epoch 6/100\n",
      " 230/7200 [..............................] - ETA: 7s - loss: 0.4774 - acc: 0.7696 \n",
      " 460/7200 [>.............................] - ETA: 5s - loss: 0.4453 - acc: 0.7913Epoch 6/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4188 - acc: 0.8232     \n",
      "Epoch 6/100\n",
      " 400/7200 [>.............................] - ETA: 3s - loss: 0.4252 - acc: 0.8125\n",
      " 690/7200 [=>............................] - ETA: 5s - loss: 0.4420 - acc: 0.8101Epoch 6/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4161 - acc: 0.8264     \n",
      "6830/7200 [===========================>..] - ETA: 0s - loss: 0.4179 - acc: 0.8242Epoch 7/100\n",
      "\n",
      "  10/7200 [..............................] - ETA: 3s - loss: 0.4760 - acc: 0.8000Epoch 7/100\n",
      "7150/7200 [============================>.] - ETA: 0s - loss: 0.4168 - acc: 0.8264\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4162 - acc: 0.8265     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4137 - acc: 0.8282     \n",
      "6710/7200 [==========================>...] - ETA: 0s - loss: 0.4156 - acc: 0.8274Epoch 7/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4172 - acc: 0.8262     \n",
      " 350/7200 [>.............................] - ETA: 4s - loss: 0.4464 - acc: 0.8057Epoch 7/100\n",
      " 430/7200 [>.............................] - ETA: 4s - loss: 0.4283 - acc: 0.8116\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4138 - acc: 0.8292     \n",
      " 610/7200 [=>............................] - ETA: 4s - loss: 0.4298 - acc: 0.8295Epoch 7/100\n",
      "6630/7200 [==========================>...] - ETA: 0s - loss: 0.4109 - acc: 0.8317\n",
      "6860/7200 [===========================>..] - ETA: 0s - loss: 0.4093 - acc: 0.8340Epoch 8/100\n",
      "6980/7200 [============================>.] - ETA: 0s - loss: 0.4162 - acc: 0.8277\n",
      "7200/7200 [==============================] - 5s - loss: 0.4148 - acc: 0.8279     \n",
      "Epoch 8/100\n",
      "  90/7200 [..............................] - ETA: 5s - loss: 0.3386 - acc: 0.8889Epoch 8/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4176 - acc: 0.8264     \n",
      " 160/7200 [..............................] - ETA: 5s - loss: 0.3634 - acc: 0.8750Epoch 8/100\n",
      "  10/7200 [..............................] - ETA: 3s - loss: 0.4795 - acc: 0.9000\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4154 - acc: 0.8289     \n",
      " 460/7200 [>.............................] - ETA: 5s - loss: 0.3842 - acc: 0.8457Epoch 8/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4150 - acc: 0.8290     \n",
      " 460/7200 [>.............................] - ETA: 6s - loss: 0.3857 - acc: 0.8587Epoch 8/100\n",
      "7200/7200 [==============================] - 6s - loss: 0.4126 - acc: 0.8308     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4143 - acc: 0.8293     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4139 - acc: 0.8306     \n",
      "6910/7200 [===========================>..] - ETA: 0s - loss: 0.4135 - acc: 0.8320Epoch 9/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4172 - acc: 0.8283     \n",
      "Epoch 9/100\n",
      "6990/7200 [============================>.] - ETA: 0s - loss: 0.4140 - acc: 0.8315\n",
      "7200/7200 [==============================] - 5s - loss: 0.4134 - acc: 0.8293     Epoch 9/100\n",
      "  80/7200 [..............................] - ETA: 10s - loss: 0.4497 - acc: 0.8375\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4140 - acc: 0.8307     \n",
      "Epoch 9/100\n",
      " 100/7200 [..............................] - ETA: 11s - loss: 0.4007 - acc: 0.8900\n",
      "Epoch 9/100\n",
      " 220/7200 [..............................] - ETA: 6s - loss: 0.3920 - acc: 0.8636\n",
      " 160/7200 [..............................] - ETA: 7s - loss: 0.3651 - acc: 0.8812Epoch 10/100\n",
      "  10/7200 [..............................] - ETA: 7s - loss: 0.2951 - acc: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.123523). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 5s - loss: 0.4103 - acc: 0.8322     \n",
      "1460/7200 [=====>........................] - ETA: 4s - loss: 0.3912 - acc: 0.8425Epoch 10/100\n",
      "7130/7200 [============================>.] - ETA: 0s - loss: 0.4166 - acc: 0.8297\n",
      "6830/7200 [===========================>..] - ETA: 0s - loss: 0.4119 - acc: 0.8318Epoch 11/100\n",
      "6680/7200 [==========================>...] - ETA: 0s - loss: 0.4132 - acc: 0.8337\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4089 - acc: 0.8339     \n",
      "Epoch 11/100\n",
      "7110/7200 [============================>.] - ETA: 0s - loss: 0.4121 - acc: 0.8325\n",
      "Epoch 11/100\n",
      "7180/7200 [============================>.] - ETA: 0s - loss: 0.4122 - acc: 0.8344\n",
      "6120/7200 [========================>.....] - ETA: 0s - loss: 0.4084 - acc: 0.8330Epoch 11/100\n",
      " 200/7200 [..............................] - ETA: 9s - loss: 0.4069 - acc: 0.8350\n",
      "  40/7200 [..............................] - ETA: 16s - loss: 0.4635 - acc: 0.7750Epoch 11/100\n",
      "6500/7200 [==========================>...] - ETA: 0s - loss: 0.4070 - acc: 0.8342\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4091 - acc: 0.8328     \n",
      "1190/7200 [===>..........................] - ETA: 4s - loss: 0.4309 - acc: 0.8311Epoch 11/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4057 - acc: 0.8354     \n",
      "6470/7200 [=========================>....] - ETA: 0s - loss: 0.4094 - acc: 0.8352Epoch 15/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4090 - acc: 0.8311     \n",
      "Epoch 15/100\n",
      "\n",
      "6810/7200 [===========================>..] - ETA: 0s - loss: 0.4090 - acc: 0.8341Epoch 15/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4084 - acc: 0.8343     \n",
      "6700/7200 [==========================>...] - ETA: 0s - loss: 0.4090 - acc: 0.8342Epoch 15/100\n",
      "6870/7200 [===========================>..] - ETA: 0s - loss: 0.4090 - acc: 0.8333\n",
      "7180/7200 [============================>.] - ETA: 0s - loss: 0.4078 - acc: 0.8348Epoch 15/100\n",
      " 690/7200 [=>............................] - ETA: 5s - loss: 0.4522 - acc: 0.8058\n",
      "Epoch 15/100\n",
      "6580/7200 [==========================>...] - ETA: 0s - loss: 0.4073 - acc: 0.8345\n",
      "6590/7200 [==========================>...] - ETA: 0s - loss: 0.4069 - acc: 0.8349Epoch 16/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4085 - acc: 0.8322     \n",
      "7200/7200 [==============================] - 5s - loss: 0.4116 - acc: 0.8317     \n",
      "  90/7200 [..............................] - ETA: 4s - loss: 0.4240 - acc: 0.8222Epoch 16/100\n",
      "6700/7200 [==========================>...] - ETA: 0s - loss: 0.4069 - acc: 0.8346Epoch 16/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4077 - acc: 0.8332     \n",
      "7200/7200 [==============================] - 5s - loss: 0.4070 - acc: 0.8340     Epoch 16/100\n",
      "\n",
      "6800/7200 [===========================>..] - ETA: 0s - loss: 0.4069 - acc: 0.8357Epoch 16/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4083 - acc: 0.8346     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4082 - acc: 0.8336     \n",
      "Epoch 16/100\n",
      "6220/7200 [========================>.....] - ETA: 0s - loss: 0.4101 - acc: 0.8315\n",
      "6000/7200 [========================>.....] - ETA: 0s - loss: 0.4096 - acc: 0.8315Epoch 17/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4082 - acc: 0.8315     \n",
      "\n",
      "Epoch 17/100\n",
      "Epoch 17/100\n",
      " 900/7200 [==>...........................] - ETA: 4s - loss: 0.3751 - acc: 0.8467\n",
      "Epoch 17/100\n",
      "1040/7200 [===>..........................] - ETA: 4s - loss: 0.3787 - acc: 0.8423\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4078 - acc: 0.8349     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4077 - acc: 0.8339     \n",
      "Epoch 17/100\n",
      "1430/7200 [====>.........................] - ETA: 4s - loss: 0.4096 - acc: 0.8301\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4035 - acc: 0.8346     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4099 - acc: 0.8300     \n",
      "6410/7200 [=========================>....] - ETA: 0s - loss: 0.4051 - acc: 0.8309Epoch 19/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4068 - acc: 0.8326     \n",
      "Epoch 19/100\n",
      " 480/7200 [=>............................] - ETA: 6s - loss: 0.3817 - acc: 0.8479\n",
      " 270/7200 [>.............................] - ETA: 2s - loss: 0.4147 - acc: 0.8111Epoch 19/100\n",
      "7150/7200 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8324\n",
      " 600/7200 [=>............................] - ETA: 5s - loss: 0.4069 - acc: 0.8383Epoch 19/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4063 - acc: 0.8329     \n",
      "6910/7200 [===========================>..] - ETA: 0s - loss: 0.4044 - acc: 0.8326Epoch 19/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4059 - acc: 0.8324     \n",
      "6300/7200 [=========================>....] - ETA: 0s - loss: 0.3998 - acc: 0.8373Epoch 19/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4038 - acc: 0.8358     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4031 - acc: 0.8342     \n",
      "6590/7200 [==========================>...] - ETA: 0s - loss: 0.4024 - acc: 0.8346Epoch 20/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4095 - acc: 0.8306     \n",
      "Epoch 20/100\n",
      " 140/7200 [..............................] - ETA: 6s - loss: 0.4201 - acc: 0.8214\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4063 - acc: 0.8342     \n",
      " 480/7200 [=>............................] - ETA: 6s - loss: 0.3876 - acc: 0.8417Epoch 20/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4054 - acc: 0.8349     \n",
      "5950/7200 [=======================>......] - ETA: 0s - loss: 0.3977 - acc: 0.8356Epoch 20/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4046 - acc: 0.8340     \n",
      "6060/7200 [========================>.....] - ETA: 0s - loss: 0.3995 - acc: 0.8345Epoch 20/100\n",
      " 310/7200 [>.............................] - ETA: 5s - loss: 0.4001 - acc: 0.8355\n",
      "6400/7200 [=========================>....] - ETA: 0s - loss: 0.4004 - acc: 0.8345Epoch 20/100\n",
      "1680/7200 [======>.......................] - ETA: 4s - loss: 0.4158 - acc: 0.8232\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4033 - acc: 0.8353     \n",
      "1570/7200 [=====>........................] - ETA: 3s - loss: 0.3902 - acc: 0.8433Epoch 21/100\n",
      " 680/7200 [=>............................] - ETA: 4s - loss: 0.4250 - acc: 0.8279\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4023 - acc: 0.8349     \n",
      "Epoch 25/100\n",
      "5360/7200 [=====================>........] - ETA: 1s - loss: 0.4019 - acc: 0.8351\n",
      "5750/7200 [======================>.......] - ETA: 1s - loss: 0.4080 - acc: 0.8323Epoch 25/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4084 - acc: 0.8315     \n",
      "Epoch 25/100\n",
      " 920/7200 [==>...........................] - ETA: 4s - loss: 0.3759 - acc: 0.8489\n",
      "6940/7200 [===========================>..] - ETA: 0s - loss: 0.4040 - acc: 0.8330Epoch 25/100\n",
      " 440/7200 [>.............................] - ETA: 4s - loss: 0.4068 - acc: 0.8432\n",
      " 940/7200 [==>...........................] - ETA: 4s - loss: 0.3740 - acc: 0.8500Epoch 25/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4042 - acc: 0.8332     \n",
      "Epoch 25/100\n",
      "1380/7200 [====>.........................] - ETA: 4s - loss: 0.4017 - acc: 0.8399\n",
      "Epoch 25/100\n",
      "1130/7200 [===>..........................] - ETA: 4s - loss: 0.3778 - acc: 0.8496\n",
      "2120/7200 [=======>......................] - ETA: 3s - loss: 0.3770 - acc: 0.8524Epoch 25/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4022 - acc: 0.8350     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4081 - acc: 0.8328     \n",
      "7200/7200 [==============================] - 4s - loss: 0.4058 - acc: 0.8346     \n",
      "Epoch 26/100\n",
      "6860/7200 [===========================>..] - ETA: 0s - loss: 0.4058 - acc: 0.8348Epoch 26/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4052 - acc: 0.8346     \n",
      "Epoch 26/100\n",
      " 560/7200 [=>............................] - ETA: 4s - loss: 0.4054 - acc: 0.8393\n",
      " 550/7200 [=>............................] - ETA: 4s - loss: 0.3700 - acc: 0.8545Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 4s - loss: 0.4038 - acc: 0.8350     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4044 - acc: 0.8360     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4022 - acc: 0.8361     \n",
      " 440/7200 [>.............................] - ETA: 4s - loss: 0.3784 - acc: 0.8636Epoch 26/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4016 - acc: 0.8361     \n",
      "Epoch 27/100\n",
      "  10/7200 [..............................] - ETA: 6s - loss: 0.4129 - acc: 0.7000\n",
      "6330/7200 [=========================>....] - ETA: 0s - loss: 0.4052 - acc: 0.8329Epoch 27/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4054 - acc: 0.8344     \n",
      "Epoch 27/100\n",
      " 460/7200 [>.............................] - ETA: 5s - loss: 0.3592 - acc: 0.8500\n",
      "Epoch 27/100\n",
      "7010/7200 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8357\n",
      "6520/7200 [==========================>...] - ETA: 0s - loss: 0.4066 - acc: 0.8325Epoch 27/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4031 - acc: 0.8351     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4038 - acc: 0.8346     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4022 - acc: 0.8349     \n",
      "Epoch 27/100\n",
      "7120/7200 [============================>.] - ETA: 0s - loss: 0.4048 - acc: 0.8344\n",
      "\n",
      "Epoch 28/100\n",
      "Epoch 28/100\n",
      "6120/7200 [========================>.....] - ETA: 0s - loss: 0.3999 - acc: 0.8348\n",
      " 100/7200 [..............................] - ETA: 4s - loss: 0.4582 - acc: 0.8200Epoch 28/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4046 - acc: 0.8337     \n",
      "Epoch 28/100\n",
      "5730/7200 [======================>.......] - ETA: 1s - loss: 0.3951 - acc: 0.8391\n",
      "6770/7200 [===========================>..] - ETA: 0s - loss: 0.4016 - acc: 0.8338Epoch 28/100\n",
      "1020/7200 [===>..........................] - ETA: 3s - loss: 0.4149 - acc: 0.8324\n",
      "1070/7200 [===>..........................] - ETA: 4s - loss: 0.3828 - acc: 0.8430Epoch 28/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4038 - acc: 0.8346     \n",
      "Epoch 28/100\n",
      "2230/7200 [========>.....................] - ETA: 3s - loss: 0.4042 - acc: 0.8359\n",
      "1340/7200 [====>.........................] - ETA: 4s - loss: 0.4190 - acc: 0.8269Epoch 28/100\n",
      "6190/7200 [========================>.....] - ETA: 0s - loss: 0.4046 - acc: 0.8370\n",
      "5930/7200 [=======================>......] - ETA: 0s - loss: 0.4042 - acc: 0.8359Epoch 29/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4033 - acc: 0.8358     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4038 - acc: 0.8357     \n",
      "6820/7200 [===========================>..] - ETA: 0s - loss: 0.4005 - acc: 0.8381Epoch 29/100\n",
      "2150/7200 [=======>......................] - ETA: 3s - loss: 0.3773 - acc: 0.8423\n",
      "Epoch 29/100\n",
      "1670/7200 [=====>........................] - ETA: 3s - loss: 0.4065 - acc: 0.8371\n",
      "1850/7200 [======>.......................] - ETA: 3s - loss: 0.4181 - acc: 0.8314Epoch 30/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4015 - acc: 0.8349     \n",
      "Epoch 30/100\n",
      "6580/7200 [==========================>...] - ETA: 0s - loss: 0.4035 - acc: 0.8345\n",
      "7200/7200 [==============================] - 4s - loss: 0.4046 - acc: 0.8340     \n",
      "Epoch 32/100\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4072 - acc: 0.8315     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4043 - acc: 0.8354     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4049 - acc: 0.8325     \n",
      "Epoch 33/100\n",
      " 140/7200 [..............................] - ETA: 2s - loss: 0.4005 - acc: 0.8429\n",
      "6080/7200 [========================>.....] - ETA: 0s - loss: 0.3982 - acc: 0.8375Epoch 33/100\n",
      "5110/7200 [====================>.........] - ETA: 1s - loss: 0.4005 - acc: 0.8346\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4043 - acc: 0.8347     \n",
      " 380/7200 [>.............................] - ETA: 4s - loss: 0.4067 - acc: 0.8237Epoch 33/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4036 - acc: 0.8336     \n",
      "Epoch 33/100\n",
      "5000/7200 [===================>..........] - ETA: 1s - loss: 0.4066 - acc: 0.8328\n",
      "7130/7200 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8332Epoch 34/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4008 - acc: 0.8361     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4065 - acc: 0.8332     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4034 - acc: 0.8354     \n",
      "Epoch 34/100\n",
      "5670/7200 [======================>.......] - ETA: 1s - loss: 0.4066 - acc: 0.8317\n",
      "6030/7200 [========================>.....] - ETA: 0s - loss: 0.4055 - acc: 0.8317Epoch 34/100\n",
      " 920/7200 [==>...........................] - ETA: 4s - loss: 0.4160 - acc: 0.8228\n",
      " 380/7200 [>.............................] - ETA: 4s - loss: 0.4000 - acc: 0.8316Epoch 34/100\n",
      "6550/7200 [==========================>...] - ETA: 0s - loss: 0.4005 - acc: 0.8356\n",
      "5950/7200 [=======================>......] - ETA: 0s - loss: 0.4000 - acc: 0.8348Epoch 35/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4008 - acc: 0.8346     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4069 - acc: 0.8318     \n",
      "6750/7200 [===========================>..] - ETA: 0s - loss: 0.4011 - acc: 0.8354Epoch 35/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4035 - acc: 0.8346     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4029 - acc: 0.8342     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4027 - acc: 0.8340     \n",
      "Epoch 35/100\n",
      "1700/7200 [======>.......................] - ETA: 3s - loss: 0.4308 - acc: 0.8206\n",
      "6870/7200 [===========================>..] - ETA: 0s - loss: 0.4002 - acc: 0.8360Epoch 35/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4029 - acc: 0.8343     \n",
      "1920/7200 [=======>......................] - ETA: 3s - loss: 0.4224 - acc: 0.8260Epoch 35/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4004 - acc: 0.8354     \n",
      "4990/7200 [===================>..........] - ETA: 1s - loss: 0.4048 - acc: 0.8343Epoch 36/100\n",
      "7010/7200 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8335\n",
      "5080/7200 [====================>.........] - ETA: 1s - loss: 0.4054 - acc: 0.8346Epoch 36/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4062 - acc: 0.8332     \n",
      "Epoch 36/100\n",
      " 470/7200 [>.............................] - ETA: 3s - loss: 0.4299 - acc: 0.8255\n",
      "7180/7200 [============================>.] - ETA: 0s - loss: 0.4026 - acc: 0.8359Epoch 36/100\n",
      "  10/7200 [..............................] - ETA: 7s - loss: 0.7386 - acc: 0.7000\n",
      "7010/7200 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8340Epoch 36/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4021 - acc: 0.8343     \n",
      "6060/7200 [========================>.....] - ETA: 0s - loss: 0.4012 - acc: 0.8361Epoch 36/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4006 - acc: 0.8351     \n",
      "1990/7200 [=======>......................] - ETA: 3s - loss: 0.3978 - acc: 0.8296Epoch 36/100\n",
      "1440/7200 [=====>........................] - ETA: 3s - loss: 0.3961 - acc: 0.8333\n",
      "2280/7200 [========>.....................] - ETA: 3s - loss: 0.4036 - acc: 0.8329Epoch 36/100\n",
      "5420/7200 [=====================>........] - ETA: 1s - loss: 0.4075 - acc: 0.8319\n",
      " 440/7200 [>.............................] - ETA: 4s - loss: 0.4015 - acc: 0.8318Epoch 37/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4031 - acc: 0.8350     \n",
      "6320/7200 [=========================>....] - ETA: 0s - loss: 0.4031 - acc: 0.8350\n",
      "Epoch 37/100\n",
      " 910/7200 [==>...........................] - ETA: 4s - loss: 0.3954 - acc: 0.8319Epoch 37/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4011 - acc: 0.8357     \n",
      "1650/7200 [=====>........................] - ETA: 3s - loss: 0.4145 - acc: 0.8315Epoch 37/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4030 - acc: 0.8354     \n",
      " 210/7200 [..............................] - ETA: 4s - loss: 0.4197 - acc: 0.8333Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 4s - loss: 0.4030 - acc: 0.8350     \n",
      "2070/7200 [=======>......................] - ETA: 3s - loss: 0.4181 - acc: 0.8237Epoch 38/100\n",
      "6920/7200 [===========================>..] - ETA: 0s - loss: 0.4084 - acc: 0.8303\n",
      "Epoch 39/100\n",
      "5180/7200 [====================>.........] - ETA: 1s - loss: 0.4074 - acc: 0.8342\n",
      "7140/7200 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8314Epoch 39/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4061 - acc: 0.8322     \n",
      "  10/7200 [..............................] - ETA: 3s - loss: 0.2451 - acc: 0.9000Epoch 39/100\n",
      "5300/7200 [=====================>........] - ETA: 1s - loss: 0.4062 - acc: 0.8342\n",
      "7100/7200 [============================>.] - ETA: 0s - loss: 0.4009 - acc: 0.8345Epoch 40/100\n",
      "6800/7200 [===========================>..] - ETA: 0s - loss: 0.4047 - acc: 0.8334\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4062 - acc: 0.8321     \n",
      "7200/7200 [==============================] - 4s - loss: 0.4035 - acc: 0.8339     \n",
      "6730/7200 [===========================>..] - ETA: 0s - loss: 0.4016 - acc: 0.8348Epoch 40/100\n",
      "5820/7200 [=======================>......] - ETA: 0s - loss: 0.4076 - acc: 0.8325Epoch 40/100\n",
      " 860/7200 [==>...........................] - ETA: 3s - loss: 0.3982 - acc: 0.8372\n",
      " 440/7200 [>.............................] - ETA: 3s - loss: 0.4083 - acc: 0.8318Epoch 40/100\n",
      " 770/7200 [==>...........................] - ETA: 3s - loss: 0.3944 - acc: 0.8338\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4008 - acc: 0.8362     \n",
      "Epoch 40/100\n",
      "6390/7200 [=========================>....] - ETA: 0s - loss: 0.4078 - acc: 0.8330\n",
      "5630/7200 [======================>.......] - ETA: 0s - loss: 0.4078 - acc: 0.8329Epoch 41/100\n",
      "5180/7200 [====================>.........] - ETA: 1s - loss: 0.4020 - acc: 0.8338\n",
      "6420/7200 [=========================>....] - ETA: 0s - loss: 0.4075 - acc: 0.8330Epoch 41/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4063 - acc: 0.8324     \n",
      "5730/7200 [======================>.......] - ETA: 0s - loss: 0.4045 - acc: 0.8330Epoch 41/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4032 - acc: 0.8349     \n",
      " 800/7200 [==>...........................] - ETA: 4s - loss: 0.3780 - acc: 0.8425Epoch 41/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4028 - acc: 0.8349     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4022 - acc: 0.8353     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4009 - acc: 0.8343     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4024 - acc: 0.8350     \n",
      " 350/7200 [>.............................] - ETA: 4s - loss: 0.3275 - acc: 0.8771Epoch 41/100\n",
      "5270/7200 [====================>.........] - ETA: 1s - loss: 0.3982 - acc: 0.8359\n",
      "Epoch 42/100\n",
      "6790/7200 [===========================>..] - ETA: 0s - loss: 0.4022 - acc: 0.8330\n",
      "Epoch 42/100\n",
      "7110/7200 [============================>.] - ETA: 0s - loss: 0.4012 - acc: 0.8357\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4020 - acc: 0.8353     \n",
      "6600/7200 [==========================>...] - ETA: 0s - loss: 0.3983 - acc: 0.8361Epoch 42/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4004 - acc: 0.8350     \n",
      "1320/7200 [====>.........................] - ETA: 4s - loss: 0.4114 - acc: 0.8182Epoch 42/100\n",
      "1880/7200 [======>.......................] - ETA: 3s - loss: 0.3999 - acc: 0.8356\n",
      "1240/7200 [====>.........................] - ETA: 3s - loss: 0.4184 - acc: 0.8226Epoch 42/100\n",
      "3360/7200 [=============>................] - ETA: 2s - loss: 0.4007 - acc: 0.8330\n",
      " 820/7200 [==>...........................] - ETA: 3s - loss: 0.3653 - acc: 0.8476Epoch 43/100\n",
      "5530/7200 [======================>.......] - ETA: 1s - loss: 0.3982 - acc: 0.8367\n",
      "6840/7200 [===========================>..] - ETA: 0s - loss: 0.4030 - acc: 0.8364Epoch 44/100\n",
      "6470/7200 [=========================>....] - ETA: 0s - loss: 0.4011 - acc: 0.8360\n",
      "Epoch 44/100\n",
      "6480/7200 [==========================>...] - ETA: 0s - loss: 0.4045 - acc: 0.8327\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4042 - acc: 0.8349     \n",
      "5990/7200 [=======================>......] - ETA: 0s - loss: 0.4057 - acc: 0.8307Epoch 45/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4030 - acc: 0.8342     \n",
      "6310/7200 [=========================>....] - ETA: 0s - loss: 0.4016 - acc: 0.8352Epoch 45/100\n",
      "1380/7200 [====>.........................] - ETA: 3s - loss: 0.3705 - acc: 0.8529\n",
      " 970/7200 [===>..........................] - ETA: 4s - loss: 0.3927 - acc: 0.8381Epoch 45/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4018 - acc: 0.8356     \n",
      "1050/7200 [===>..........................] - ETA: 5s - loss: 0.3976 - acc: 0.8362Epoch 45/100\n",
      "1290/7200 [====>.........................] - ETA: 4s - loss: 0.3844 - acc: 0.8426\n",
      " 310/7200 [>.............................] - ETA: 5s - loss: 0.4027 - acc: 0.8258Epoch 45/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4005 - acc: 0.8358     \n",
      "1710/7200 [======>.......................] - ETA: 3s - loss: 0.3899 - acc: 0.8386Epoch 45/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3999 - acc: 0.8340     \n",
      "Epoch 46/100\n",
      " 270/7200 [>.............................] - ETA: 5s - loss: 0.4297 - acc: 0.8148\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4031 - acc: 0.8340     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4026 - acc: 0.8336     \n",
      "Epoch 46/100\n",
      "5650/7200 [======================>.......] - ETA: 1s - loss: 0.4042 - acc: 0.8331\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46/100\n",
      " 820/7200 [==>...........................] - ETA: 4s - loss: 0.3891 - acc: 0.8415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.121828). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 4s - loss: 0.3999 - acc: 0.8349     \n",
      "6260/7200 [=========================>....] - ETA: 0s - loss: 0.4020 - acc: 0.8351Epoch 46/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4024 - acc: 0.8342     \n",
      "2150/7200 [=======>......................] - ETA: 3s - loss: 0.3951 - acc: 0.8372Epoch 46/100\n",
      "4010/7200 [===============>..............] - ETA: 2s - loss: 0.3895 - acc: 0.8451Epoch 47/100\n",
      "1440/7200 [=====>........................] - ETA: 3s - loss: 0.3571 - acc: 0.8493\n",
      " 160/7200 [..............................] - ETA: 5s - loss: 0.3331 - acc: 0.8875Epoch 47/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3997 - acc: 0.8353     \n",
      " 470/7200 [>.............................] - ETA: 3s - loss: 0.3256 - acc: 0.8596Epoch 47/100\n",
      "1720/7200 [======>.......................] - ETA: 3s - loss: 0.3683 - acc: 0.8512\n",
      "Epoch 47/100\n",
      "5190/7200 [====================>.........] - ETA: 1s - loss: 0.3975 - acc: 0.8370"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.607856). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/7200 [..............................] - ETA: 230s - loss: 0.5436 - acc: 0.7500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.306687). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 5s - loss: 0.3998 - acc: 0.8354     0\n",
      "Epoch 48/100\n",
      "3070/7200 [===========>..................] - ETA: 3s - loss: 0.3894 - acc: 0.8375\n",
      "1570/7200 [=====>........................] - ETA: 6s - loss: 0.3814 - acc: 0.8465Epoch 48/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4038 - acc: 0.8354     \n",
      "\n",
      "Epoch 49/100\n",
      "6540/7200 [==========================>...] - ETA: 0s - loss: 0.4031 - acc: 0.8350Epoch 49/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4035 - acc: 0.8344     \n",
      "Epoch 49/100\n",
      "6810/7200 [===========================>..] - ETA: 0s - loss: 0.4003 - acc: 0.8366\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4018 - acc: 0.8349     \n",
      "5220/7200 [====================>.........] - ETA: 1s - loss: 0.3988 - acc: 0.8360Epoch 49/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4023 - acc: 0.8339     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3998 - acc: 0.8367     \n",
      "1360/7200 [====>.........................] - ETA: 4s - loss: 0.4127 - acc: 0.8235Epoch 49/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4024 - acc: 0.8350     \n",
      "Epoch 49/100\n",
      "5570/7200 [======================>.......] - ETA: 1s - loss: 0.3986 - acc: 0.8354\n",
      "Epoch 50/100\n",
      "6210/7200 [========================>.....] - ETA: 0s - loss: 0.4010 - acc: 0.8345\n",
      "6720/7200 [===========================>..] - ETA: 0s - loss: 0.4023 - acc: 0.8347Epoch 50/100\n",
      "6750/7200 [===========================>..] - ETA: 0s - loss: 0.3994 - acc: 0.8353\n",
      "6310/7200 [=========================>....] - ETA: 0s - loss: 0.4018 - acc: 0.8338Epoch 50/100\n",
      "5060/7200 [====================>.........] - ETA: 1s - loss: 0.4038 - acc: 0.8326\n",
      "\n",
      "Epoch 50/100\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4028 - acc: 0.8347     \n",
      "7200/7200 [==============================] - 4s - loss: 0.3997 - acc: 0.8347     Epoch 50/100\n",
      "5560/7200 [======================>.......] - ETA: 1s - loss: 0.4024 - acc: 0.8329\n",
      "  10/7200 [..............................] - ETA: 2s - loss: 0.3226 - acc: 0.9000Epoch 50/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4026 - acc: 0.8343     \n",
      "Epoch 50/100\n",
      "6180/7200 [========================>.....] - ETA: 0s - loss: 0.4032 - acc: 0.8338\n",
      "3730/7200 [==============>...............] - ETA: 2s - loss: 0.3992 - acc: 0.8340Epoch 51/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4001 - acc: 0.8339     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4030 - acc: 0.8344     \n",
      "Epoch 51/100\n",
      "1100/7200 [===>..........................] - ETA: 4s - loss: 0.4046 - acc: 0.8400\n",
      "Epoch 51/100\n",
      "6750/7200 [===========================>..] - ETA: 0s - loss: 0.4029 - acc: 0.8342\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3992 - acc: 0.8358     \n",
      "Epoch 51/100\n",
      "1840/7200 [======>.......................] - ETA: 3s - loss: 0.4031 - acc: 0.8359\n",
      " 610/7200 [=>............................] - ETA: 3s - loss: 0.4239 - acc: 0.8393Epoch 51/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4022 - acc: 0.8331     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4059 - acc: 0.8336     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4027 - acc: 0.8346     \n",
      "Epoch 52/100\n",
      "7120/7200 [============================>.] - ETA: 0s - loss: 0.4014 - acc: 0.8348\n",
      "Epoch 52/100\n",
      "1420/7200 [====>.........................] - ETA: 4s - loss: 0.4118 - acc: 0.8218\n",
      "1050/7200 [===>..........................] - ETA: 3s - loss: 0.4119 - acc: 0.8257Epoch 52/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4019 - acc: 0.8358     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4023 - acc: 0.8353     \n",
      "3940/7200 [===============>..............] - ETA: 1s - loss: 0.4058 - acc: 0.8272Epoch 53/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4029 - acc: 0.8336     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4015 - acc: 0.8343     \n",
      "2630/7200 [=========>....................] - ETA: 3s - loss: 0.4119 - acc: 0.8346Epoch 54/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4029 - acc: 0.8343     \n",
      "Epoch 55/100\n",
      "3660/7200 [==============>...............] - ETA: 2s - loss: 0.4025 - acc: 0.8410\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4054 - acc: 0.8318     \n",
      "Epoch 55/100\n",
      "6510/7200 [==========================>...] - ETA: 0s - loss: 0.4021 - acc: 0.8343\n",
      "6510/7200 [==========================>...] - ETA: 0s - loss: 0.4006 - acc: 0.8359\n",
      "Epoch 56/100\n",
      "6420/7200 [=========================>....] - ETA: 0s - loss: 0.4040 - acc: 0.8343\n",
      "6140/7200 [========================>.....] - ETA: 0s - loss: 0.4030 - acc: 0.8353Epoch 56/100\n",
      "6430/7200 [=========================>....] - ETA: 0s - loss: 0.3986 - acc: 0.8358\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4019 - acc: 0.8358     \n",
      "7130/7200 [============================>.] - ETA: 0s - loss: 0.4039 - acc: 0.8332Epoch 56/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4031 - acc: 0.8339     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4031 - acc: 0.8358     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4003 - acc: 0.8353     \n",
      "Epoch 57/100\n",
      "6600/7200 [==========================>...] - ETA: 0s - loss: 0.3997 - acc: 0.8356\n",
      "6810/7200 [===========================>..] - ETA: 0s - loss: 0.4003 - acc: 0.8357Epoch 57/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4013 - acc: 0.8335     \n",
      "Epoch 57/100\n",
      "7010/7200 [============================>.] - ETA: 0s - loss: 0.4005 - acc: 0.8350\n",
      " 370/7200 [>.............................] - ETA: 3s - loss: 0.3803 - acc: 0.8378Epoch 57/100\n",
      "1700/7200 [======>.......................] - ETA: 3s - loss: 0.3626 - acc: 0.8612\n",
      "6880/7200 [===========================>..] - ETA: 0s - loss: 0.3973 - acc: 0.8334Epoch 57/100\n",
      "6480/7200 [==========================>...] - ETA: 0s - loss: 0.3957 - acc: 0.8380\n",
      "5300/7200 [=====================>........] - ETA: 1s - loss: 0.3960 - acc: 0.8379Epoch 58/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3995 - acc: 0.8351     \n",
      "6640/7200 [==========================>...] - ETA: 0s - loss: 0.4030 - acc: 0.8333Epoch 58/100\n",
      "6400/7200 [=========================>....] - ETA: 0s - loss: 0.3960 - acc: 0.8362\n",
      "\n",
      "6740/7200 [===========================>..] - ETA: 0s - loss: 0.3979 - acc: 0.8372Epoch 58/100\n",
      " 670/7200 [=>............................] - ETA: 4s - loss: 0.3784 - acc: 0.8537Epoch 58/100\n",
      " 500/7200 [=>............................] - ETA: 3s - loss: 0.3793 - acc: 0.8480\n",
      " 650/7200 [=>............................] - ETA: 2s - loss: 0.3899 - acc: 0.8415Epoch 58/100\n",
      "6980/7200 [============================>.] - ETA: 0s - loss: 0.3966 - acc: 0.8350\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3984 - acc: 0.8335     \n",
      "Epoch 58/100\n",
      "4930/7200 [===================>..........] - ETA: 1s - loss: 0.3979 - acc: 0.8365\n",
      "2810/7200 [==========>...................] - ETA: 2s - loss: 0.3997 - acc: 0.8377Epoch 59/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4001 - acc: 0.8346     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4052 - acc: 0.8322     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4012 - acc: 0.8358     \n",
      " 150/7200 [..............................] - ETA: 5s - loss: 0.4255 - acc: 0.8267Epoch 59/100\n",
      "6970/7200 [============================>.] - ETA: 0s - loss: 0.4033 - acc: 0.8343\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4023 - acc: 0.8350     \n",
      "1190/7200 [===>..........................] - ETA: 5s - loss: 0.3980 - acc: 0.8378Epoch 59/100\n",
      " 950/7200 [==>...........................] - ETA: 6s - loss: 0.4099 - acc: 0.8263\n",
      "Epoch 59/100\n",
      "6550/7200 [==========================>...] - ETA: 0s - loss: 0.3990 - acc: 0.8353\n",
      "6000/7200 [========================>.....] - ETA: 0s - loss: 0.4069 - acc: 0.8327Epoch 60/100\n",
      "7030/7200 [============================>.] - ETA: 0s - loss: 0.4016 - acc: 0.8341\n",
      "6340/7200 [=========================>....] - ETA: 0s - loss: 0.4035 - acc: 0.8334Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 4s - loss: 0.4010 - acc: 0.8346     \n",
      " 620/7200 [=>............................] - ETA: 4s - loss: 0.3663 - acc: 0.8565Epoch 60/100\n",
      " 540/7200 [=>............................] - ETA: 3s - loss: 0.4079 - acc: 0.8333\n",
      "1170/7200 [===>..........................] - ETA: 3s - loss: 0.3871 - acc: 0.8410Epoch 60/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4019 - acc: 0.8349     \n",
      "Epoch 60/100\n",
      " 280/7200 [>.............................] - ETA: 4s - loss: 0.3360 - acc: 0.9000\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4016 - acc: 0.8356     \n",
      "Epoch 60/100\n",
      "4420/7200 [=================>............] - ETA: 1s - loss: 0.4039 - acc: 0.8339\n",
      "Epoch 61/100\n",
      " 110/7200 [..............................] - ETA: 3s - loss: 0.3187 - acc: 0.8818\n",
      "1150/7200 [===>..........................] - ETA: 4s - loss: 0.3914 - acc: 0.8365Epoch 61/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3984 - acc: 0.8354     \n",
      "1460/7200 [=====>........................] - ETA: 4s - loss: 0.3828 - acc: 0.8411Epoch 61/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4017 - acc: 0.8351     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4016 - acc: 0.8335     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4025 - acc: 0.8365     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4000 - acc: 0.8349     \n",
      "Epoch 63/100\n",
      "3390/7200 [=============>................] - ETA: 2s - loss: 0.3961 - acc: 0.8381\n",
      "Epoch 63/100\n",
      "5130/7200 [====================>.........] - ETA: 1s - loss: 0.3940 - acc: 0.8386\n",
      "5150/7200 [====================>.........] - ETA: 1s - loss: 0.3987 - acc: 0.8363Epoch 64/100\n",
      "6150/7200 [========================>.....] - ETA: 0s - loss: 0.3972 - acc: 0.8382\n",
      "5900/7200 [=======================>......] - ETA: 0s - loss: 0.3998 - acc: 0.8393Epoch 64/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4050 - acc: 0.8326     \n",
      "4000/7200 [===============>..............] - ETA: 1s - loss: 0.4059 - acc: 0.8370Epoch 64/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4011 - acc: 0.8356     \n",
      "Epoch 64/100\n",
      "2170/7200 [========>.....................] - ETA: 3s - loss: 0.4057 - acc: 0.8263\n",
      "7090/7200 [============================>.] - ETA: 0s - loss: 0.3980 - acc: 0.8340Epoch 64/100\n",
      "2180/7200 [========>.....................] - ETA: 3s - loss: 0.4057 - acc: 0.8261\n",
      "Epoch 64/100\n",
      " 430/7200 [>.............................] - ETA: 3s - loss: 0.3877 - acc: 0.8372\n",
      "1500/7200 [=====>........................] - ETA: 3s - loss: 0.4028 - acc: 0.8267Epoch 64/100\n",
      "3220/7200 [============>.................] - ETA: 2s - loss: 0.4011 - acc: 0.8360\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4021 - acc: 0.8350     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4000 - acc: 0.8333     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4021 - acc: 0.8347     \n",
      "Epoch 66/100\n",
      "6320/7200 [=========================>....] - ETA: 0s - loss: 0.4043 - acc: 0.8304\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4049 - acc: 0.8304     \n",
      "\n",
      "Epoch 66/100\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4020 - acc: 0.8339     \n",
      "6680/7200 [==========================>...] - ETA: 0s - loss: 0.4024 - acc: 0.8311Epoch 66/100\n",
      " 410/7200 [>.............................] - ETA: 4s - loss: 0.3976 - acc: 0.8561\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.3982 - acc: 0.8343     \n",
      "4460/7200 [=================>............] - ETA: 1s - loss: 0.4101 - acc: 0.8332Epoch 66/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4019 - acc: 0.8357     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4020 - acc: 0.8343     \n",
      "Epoch 67/100\n",
      "5180/7200 [====================>.........] - ETA: 1s - loss: 0.4011 - acc: 0.8336\n",
      "6180/7200 [========================>.....] - ETA: 0s - loss: 0.4051 - acc: 0.8312Epoch 67/100\n",
      "6870/7200 [===========================>..] - ETA: 0s - loss: 0.4033 - acc: 0.8341\n",
      "\n",
      "Epoch 67/100\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4016 - acc: 0.8360     \n",
      "1290/7200 [====>.........................] - ETA: 4s - loss: 0.3812 - acc: 0.8364Epoch 67/100\n",
      "6570/7200 [==========================>...] - ETA: 0s - loss: 0.3982 - acc: 0.8327\n",
      "7140/7200 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8356Epoch 68/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4009 - acc: 0.8351     \n",
      "1440/7200 [=====>........................] - ETA: 3s - loss: 0.4072 - acc: 0.8437Epoch 68/100\n",
      "1650/7200 [=====>........................] - ETA: 3s - loss: 0.4128 - acc: 0.8303\n",
      "3440/7200 [=============>................] - ETA: 2s - loss: 0.4108 - acc: 0.8326Epoch 68/100\n",
      "3550/7200 [=============>................] - ETA: 2s - loss: 0.4072 - acc: 0.8344\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3979 - acc: 0.8332     \n",
      "Epoch 68/100\n",
      "3370/7200 [=============>................] - ETA: 2s - loss: 0.4096 - acc: 0.8309\n",
      "3610/7200 [==============>...............] - ETA: 2s - loss: 0.4055 - acc: 0.8296Epoch 68/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3975 - acc: 0.8361     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4027 - acc: 0.8342     \n",
      "3790/7200 [==============>...............] - ETA: 2s - loss: 0.4105 - acc: 0.8280Epoch 69/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4019 - acc: 0.8344     \n",
      "Epoch 69/100\n",
      "3630/7200 [==============>...............] - ETA: 2s - loss: 0.4049 - acc: 0.8317\n",
      "5440/7200 [=====================>........] - ETA: 1s - loss: 0.4016 - acc: 0.8325Epoch 70/100\n",
      "5380/7200 [=====================>........] - ETA: 1s - loss: 0.4034 - acc: 0.8329\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4001 - acc: 0.8328     \n",
      "5500/7200 [=====================>........] - ETA: 1s - loss: 0.4041 - acc: 0.8329Epoch 71/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4020 - acc: 0.8337     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3997 - acc: 0.8340     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4019 - acc: 0.8356     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4011 - acc: 0.8342     \n",
      "Epoch 72/100\n",
      "6600/7200 [==========================>...] - ETA: 0s - loss: 0.3968 - acc: 0.8359\n",
      "3090/7200 [===========>..................] - ETA: 2s - loss: 0.3993 - acc: 0.8337Epoch 72/100\n",
      " 130/7200 [..............................] - ETA: 9s - loss: 0.3593 - acc: 0.8615\n",
      "Epoch 72/100\n",
      "1780/7200 [======>.......................] - ETA: 3s - loss: 0.3892 - acc: 0.8348\n",
      " 190/7200 [..............................] - ETA: 8s - loss: 0.3976 - acc: 0.8474Epoch 72/100\n",
      " 580/7200 [=>............................] - ETA: 4s - loss: 0.3723 - acc: 0.8603\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3989 - acc: 0.8344     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4017 - acc: 0.8342     \n",
      " 260/7200 [>.............................] - ETA: 2s - loss: 0.3990 - acc: 0.8346Epoch 73/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4047 - acc: 0.8321     \n",
      "Epoch 73/100\n",
      "6930/7200 [===========================>..] - ETA: 0s - loss: 0.3959 - acc: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.639897). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7190/7200 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8345Epoch 73/100\n",
      "1740/7200 [======>.......................] - ETA: 5s - loss: 0.4068 - acc: 0.8253\n",
      "  10/7200 [..............................] - ETA: 2s - loss: 0.2334 - acc: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.356478). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.3979 - acc: 0.8351     \n",
      "Epoch 73/100\n",
      "4350/7200 [=================>............] - ETA: 1s - loss: 0.4038 - acc: 0.8336\n",
      "Epoch 73/100\n",
      "5800/7200 [=======================>......] - ETA: 0s - loss: 0.4025 - acc: 0.8341\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4016 - acc: 0.8340     \n",
      "Epoch 74/100\n",
      "7080/7200 [============================>.] - ETA: 0s - loss: 0.4055 - acc: 0.8322\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3976 - acc: 0.8335     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4049 - acc: 0.8324     \n",
      "Epoch 74/100\n",
      " 220/7200 [..............................] - ETA: 5s - loss: 0.4573 - acc: 0.8045 \n",
      "1690/7200 [======>.......................] - ETA: 3s - loss: 0.4202 - acc: 0.8314Epoch 74/100\n",
      "3220/7200 [============>.................] - ETA: 2s - loss: 0.4065 - acc: 0.8286\n",
      "1780/7200 [======>.......................] - ETA: 3s - loss: 0.4177 - acc: 0.8303Epoch 74/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4019 - acc: 0.8350     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4017 - acc: 0.8344     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3995 - acc: 0.8339     \n",
      "Epoch 76/100\n",
      "1390/7200 [====>.........................] - ETA: 3s - loss: 0.3871 - acc: 0.8381\n",
      "  10/7200 [..............................] - ETA: 3s - loss: 0.2000 - acc: 1.0000Epoch 76/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4048 - acc: 0.8319     \n",
      "Epoch 76/100\n",
      "1170/7200 [===>..........................] - ETA: 3s - loss: 0.4186 - acc: 0.8256\n",
      "1230/7200 [====>.........................] - ETA: 3s - loss: 0.3952 - acc: 0.8423Epoch 76/100\n",
      "1430/7200 [====>.........................] - ETA: 3s - loss: 0.4142 - acc: 0.8259\n",
      " 310/7200 [>.............................] - ETA: 4s - loss: 0.4386 - acc: 0.8258Epoch 76/100\n",
      " 420/7200 [>.............................] - ETA: 4s - loss: 0.4285 - acc: 0.8190\n",
      "7010/7200 [============================>.] - ETA: 0s - loss: 0.4004 - acc: 0.8342Epoch 76/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4016 - acc: 0.8331     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4017 - acc: 0.8344     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4014 - acc: 0.8368     \n",
      "1160/7200 [===>..........................] - ETA: 3s - loss: 0.3904 - acc: 0.8483Epoch 78/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3998 - acc: 0.8357     \n",
      "  60/7200 [..............................] - ETA: 8s - loss: 0.5193 - acc: 0.8167 Epoch 78/100\n",
      "6750/7200 [===========================>..] - ETA: 0s - loss: 0.4039 - acc: 0.8353\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4008 - acc: 0.8365     \n",
      "2500/7200 [=========>....................] - ETA: 3s - loss: 0.3933 - acc: 0.8408Epoch 78/100\n",
      "7050/7200 [============================>.] - ETA: 0s - loss: 0.4026 - acc: 0.8348\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4021 - acc: 0.8347     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4020 - acc: 0.8349     \n",
      " 110/7200 [..............................] - ETA: 6s - loss: 0.4781 - acc: 0.8182Epoch 78/100\n",
      "6650/7200 [==========================>...] - ETA: 0s - loss: 0.3984 - acc: 0.8380\n",
      "1190/7200 [===>..........................] - ETA: 3s - loss: 0.3770 - acc: 0.8479Epoch 79/100\n",
      "6660/7200 [==========================>...] - ETA: 0s - loss: 0.3978 - acc: 0.8375\n",
      "Epoch 79/100\n",
      "7110/7200 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8367\n",
      "7130/7200 [============================>.] - ETA: 0s - loss: 0.4004 - acc: 0.8356Epoch 79/100\n",
      " 500/7200 [=>............................] - ETA: 4s - loss: 0.3874 - acc: 0.8520\n",
      "1990/7200 [=======>......................] - ETA: 3s - loss: 0.4018 - acc: 0.8397Epoch 79/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4014 - acc: 0.8364     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4020 - acc: 0.8336     \n",
      "2050/7200 [=======>......................] - ETA: 3s - loss: 0.4265 - acc: 0.8137Epoch 80/100\n",
      "6420/7200 [=========================>....] - ETA: 0s - loss: 0.4029 - acc: 0.8315\n",
      "5060/7200 [====================>.........] - ETA: 1s - loss: 0.4144 - acc: 0.8261Epoch 80/100\n",
      "5320/7200 [=====================>........] - ETA: 1s - loss: 0.4095 - acc: 0.8276\n",
      "4970/7200 [===================>..........] - ETA: 1s - loss: 0.4151 - acc: 0.8252Epoch 81/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4011 - acc: 0.8339     \n",
      "4090/7200 [================>.............] - ETA: 1s - loss: 0.3949 - acc: 0.8379Epoch 81/100\n",
      "4700/7200 [==================>...........] - ETA: 1s - loss: 0.4002 - acc: 0.8355\n",
      "7200/7200 [==============================] - 4s - loss: 0.3992 - acc: 0.8347     Epoch 82/100\n",
      "\n",
      "Epoch 82/100\n",
      "6650/7200 [==========================>...] - ETA: 0s - loss: 0.3957 - acc: 0.8367\n",
      "7080/7200 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8325Epoch 82/100\n",
      "6850/7200 [===========================>..] - ETA: 0s - loss: 0.4015 - acc: 0.8349\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4009 - acc: 0.8351     \n",
      "4570/7200 [==================>...........] - ETA: 1s - loss: 0.3964 - acc: 0.8389Epoch 83/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3992 - acc: 0.8340     \n",
      "Epoch 83/100\n",
      "1680/7200 [======>.......................] - ETA: 3s - loss: 0.4138 - acc: 0.8238\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4045 - acc: 0.8322     \n",
      "2100/7200 [=======>......................] - ETA: 3s - loss: 0.4111 - acc: 0.8271Epoch 83/100\n",
      "7080/7200 [============================>.] - ETA: 0s - loss: 0.3978 - acc: 0.8329\n",
      "1700/7200 [======>.......................] - ETA: 4s - loss: 0.3953 - acc: 0.8388Epoch 83/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3974 - acc: 0.8335     \n",
      "Epoch 83/100\n",
      "3130/7200 [============>.................] - ETA: 2s - loss: 0.4019 - acc: 0.8364\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4012 - acc: 0.8344     \n",
      "5480/7200 [=====================>........] - ETA: 1s - loss: 0.4020 - acc: 0.8354Epoch 83/100\n",
      "5660/7200 [======================>.......] - ETA: 0s - loss: 0.4020 - acc: 0.8362\n",
      "Epoch 84/100\n",
      " 500/7200 [=>............................] - ETA: 3s - loss: 0.4404 - acc: 0.8120\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4008 - acc: 0.8353     \n",
      "Epoch 84/100\n",
      "6650/7200 [==========================>...] - ETA: 0s - loss: 0.3969 - acc: 0.8370\n",
      "6810/7200 [===========================>..] - ETA: 0s - loss: 0.3991 - acc: 0.8347Epoch 84/100\n",
      "7010/7200 [============================>.] - ETA: 0s - loss: 0.3982 - acc: 0.8352\n",
      "Epoch 84/100\n",
      " 550/7200 [=>............................] - ETA: 3s - loss: 0.4223 - acc: 0.8236\n",
      "6580/7200 [==========================>...] - ETA: 0s - loss: 0.3998 - acc: 0.8342Epoch 84/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4019 - acc: 0.8328     \n",
      "1340/7200 [====>.........................] - ETA: 3s - loss: 0.4234 - acc: 0.8246Epoch 84/100\n",
      "4710/7200 [==================>...........] - ETA: 1s - loss: 0.3940 - acc: 0.8365\n",
      "7100/7200 [============================>.] - ETA: 0s - loss: 0.3979 - acc: 0.8335Epoch 84/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3988 - acc: 0.8332     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4012 - acc: 0.8353     \n",
      "Epoch 85/100\n",
      "6690/7200 [==========================>...] - ETA: 0s - loss: 0.3989 - acc: 0.8341\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4045 - acc: 0.8335     \n",
      "Epoch 85/100\n",
      "2180/7200 [========>.....................] - ETA: 3s - loss: 0.4157 - acc: 0.8257\n",
      "2310/7200 [========>.....................] - ETA: 3s - loss: 0.3987 - acc: 0.8299Epoch 85/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4010 - acc: 0.8326     \n",
      "Epoch 85/100\n",
      "2010/7200 [=======>......................] - ETA: 3s - loss: 0.3931 - acc: 0.8393\n",
      "6400/7200 [=========================>....] - ETA: 0s - loss: 0.3987 - acc: 0.8333Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2070/7200 [=======>......................] - ETA: 3s - loss: 0.3916 - acc: 0.8406\n",
      "2280/7200 [========>.....................] - ETA: 3s - loss: 0.3966 - acc: 0.8377Epoch 86/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4017 - acc: 0.8335     \n",
      " 600/7200 [=>............................] - ETA: 4s - loss: 0.4099 - acc: 0.8167Epoch 86/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4012 - acc: 0.8351     \n",
      "7180/7200 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8357Epoch 87/100\n",
      "7150/7200 [============================>.] - ETA: 0s - loss: 0.4005 - acc: 0.8352\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4015 - acc: 0.8347     \n",
      "Epoch 86/100\n",
      "6570/7200 [==========================>...] - ETA: 0s - loss: 0.4041 - acc: 0.8332\n",
      "7200/7200 [==============================] - 4s - loss: 0.4051 - acc: 0.8324     \n",
      "6930/7200 [===========================>..] - ETA: 0s - loss: 0.3986 - acc: 0.8343Epoch 87/100\n",
      "5730/7200 [======================>.......] - ETA: 1s - loss: 0.4035 - acc: 0.8337Epoch 87/100\n",
      "5960/7200 [=======================>......] - ETA: 0s - loss: 0.4050 - acc: 0.8320\n",
      "1820/7200 [======>.......................] - ETA: 4s - loss: 0.3972 - acc: 0.8341Epoch 87/100\n",
      "2040/7200 [=======>......................] - ETA: 3s - loss: 0.3881 - acc: 0.8402\n",
      " 570/7200 [=>............................] - ETA: 4s - loss: 0.3784 - acc: 0.8421Epoch 87/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4021 - acc: 0.8344     \n",
      "Epoch 87/100\n",
      "3190/7200 [============>.................] - ETA: 2s - loss: 0.4103 - acc: 0.8273\n",
      "3200/7200 [============>.................] - ETA: 2s - loss: 0.4101 - acc: 0.8272Epoch 88/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3995 - acc: 0.8339     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4009 - acc: 0.8349     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4016 - acc: 0.8331     \n",
      " 300/7200 [>.............................] - ETA: 3s - loss: 0.3778 - acc: 0.8500Epoch 88/100\n",
      "5630/7200 [======================>.......] - ETA: 1s - loss: 0.4048 - acc: 0.8323\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3985 - acc: 0.8346     \n",
      "6830/7200 [===========================>..] - ETA: 0s - loss: 0.4013 - acc: 0.8344Epoch 90/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4016 - acc: 0.8347     \n",
      "Epoch 89/100\n",
      "5220/7200 [====================>.........] - ETA: 1s - loss: 0.4057 - acc: 0.8303\n",
      "7100/7200 [============================>.] - ETA: 0s - loss: 0.3988 - acc: 0.8346Epoch 90/100\n",
      "1830/7200 [======>.......................] - ETA: 3s - loss: 0.4117 - acc: 0.8333\n",
      "6960/7200 [============================>.] - ETA: 0s - loss: 0.4038 - acc: 0.8320Epoch 90/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4040 - acc: 0.8329     \n",
      "\n",
      "Epoch 90/100\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3993 - acc: 0.8358     \n",
      "Epoch 91/100\n",
      "5690/7200 [======================>.......] - ETA: 1s - loss: 0.4009 - acc: 0.8353\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4013 - acc: 0.8340     \n",
      "Epoch 90/100\n",
      "1480/7200 [=====>........................] - ETA: 3s - loss: 0.4019 - acc: 0.8399\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4004 - acc: 0.8354     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4014 - acc: 0.8346     \n",
      "Epoch 91/100\n",
      "1700/7200 [======>.......................] - ETA: 3s - loss: 0.4150 - acc: 0.8329\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.3996 - acc: 0.8347     \n",
      "5730/7200 [======================>.......] - ETA: 1s - loss: 0.3989 - acc: 0.8358Epoch 92/100\n",
      "  10/7200 [..............................] - ETA: 6s - loss: 0.3983 - acc: 0.8000\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4016 - acc: 0.8353     \n",
      "Epoch 91/100\n",
      "1440/7200 [=====>........................] - ETA: 3s - loss: 0.3870 - acc: 0.8431\n",
      "7160/7200 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8363Epoch 92/100\n",
      "1610/7200 [=====>........................] - ETA: 3s - loss: 0.3939 - acc: 0.8298\n",
      "6870/7200 [===========================>..] - ETA: 0s - loss: 0.4054 - acc: 0.8333Epoch 92/100\n",
      "5420/7200 [=====================>........] - ETA: 1s - loss: 0.4034 - acc: 0.8341\n",
      "7200/7200 [==============================] - 5s - loss: 0.4019 - acc: 0.8343     \n",
      "Epoch 92/100\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4021 - acc: 0.8346     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3990 - acc: 0.8350     \n",
      "5680/7200 [======================>.......] - ETA: 0s - loss: 0.4012 - acc: 0.8356Epoch 93/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4004 - acc: 0.8360     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4018 - acc: 0.8361     \n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3973 - acc: 0.8350     \n",
      "Epoch 93/100\n",
      "6580/7200 [==========================>...] - ETA: 0s - loss: 0.4090 - acc: 0.8309\n",
      "Epoch 93/100\n",
      " 580/7200 [=>............................] - ETA: 3s - loss: 0.3911 - acc: 0.8431\n",
      "2120/7200 [=======>......................] - ETA: 3s - loss: 0.3982 - acc: 0.8349Epoch 93/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4044 - acc: 0.8336     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4014 - acc: 0.8347     \n",
      "Epoch 94/100\n",
      "5740/7200 [======================>.......] - ETA: 0s - loss: 0.3951 - acc: 0.8392\n",
      "3130/7200 [============>.................] - ETA: 2s - loss: 0.3954 - acc: 0.8351Epoch 95/100\n",
      "  80/7200 [..............................] - ETA: 5s - loss: 0.4002 - acc: 0.8375\n",
      "Epoch 95/100\n",
      " 400/7200 [>.............................] - ETA: 3s - loss: 0.4179 - acc: 0.8175\n",
      "Epoch 94/100\n",
      "5910/7200 [=======================>......] - ETA: 0s - loss: 0.3995 - acc: 0.8349\n",
      "Epoch 96/100\n",
      "6760/7200 [===========================>..] - ETA: 0s - loss: 0.3974 - acc: 0.8377\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4012 - acc: 0.8349     \n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4003 - acc: 0.8353     \n",
      "1400/7200 [====>.........................] - ETA: 3s - loss: 0.4049 - acc: 0.8329Epoch 96/100\n",
      "1010/7200 [===>..........................] - ETA: 4s - loss: 0.4025 - acc: 0.8178\n",
      "1260/7200 [====>.........................] - ETA: 4s - loss: 0.4113 - acc: 0.8302Epoch 96/100\n",
      " 840/7200 [==>...........................] - ETA: 3s - loss: 0.3879 - acc: 0.8417\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.3992 - acc: 0.8344     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4004 - acc: 0.8358     \n",
      "Epoch 97/100\n",
      "5710/7200 [======================>.......] - ETA: 0s - loss: 0.4042 - acc: 0.8329\n",
      "5670/7200 [======================>.......] - ETA: 0s - loss: 0.4058 - acc: 0.8317Epoch 96/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4003 - acc: 0.8343     \n",
      " 500/7200 [=>............................] - ETA: 4s - loss: 0.4131 - acc: 0.8340Epoch 97/100\n",
      "4560/7200 [==================>...........] - ETA: 1s - loss: 0.4038 - acc: 0.8336\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4042 - acc: 0.8324     \n",
      "1700/7200 [======>.......................] - ETA: 3s - loss: 0.4055 - acc: 0.8341Epoch 97/100\n",
      "\n",
      " 750/7200 [==>...........................] - ETA: 4s - loss: 0.4007 - acc: 0.8373Epoch 97/100\n",
      "1930/7200 [=======>......................] - ETA: 3s - loss: 0.4245 - acc: 0.8259\n",
      "3830/7200 [==============>...............] - ETA: 2s - loss: 0.3998 - acc: 0.8326Epoch 97/100\n",
      " 900/7200 [==>...........................] - ETA: 3s - loss: 0.4102 - acc: 0.8289\n",
      "6550/7200 [==========================>...] - ETA: 0s - loss: 0.4016 - acc: 0.8337Epoch 98/100\n",
      " 390/7200 [>.............................] - ETA: 3s - loss: 0.3901 - acc: 0.8282\n",
      "5860/7200 [=======================>......] - ETA: 0s - loss: 0.3965 - acc: 0.8375Epoch 97/100\n",
      "6270/7200 [=========================>....] - ETA: 0s - loss: 0.3998 - acc: 0.8352\n",
      "Epoch 98/100\n",
      " 650/7200 [=>............................] - ETA: 4s - loss: 0.4309 - acc: 0.8169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 940/7200 [==>...........................] - ETA: 4s - loss: 0.4108 - acc: 0.8309Epoch 98/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4012 - acc: 0.8342     \n",
      "1900/7200 [======>.......................] - ETA: 3s - loss: 0.3940 - acc: 0.8384Epoch 98/100\n",
      "1370/7200 [====>.........................] - ETA: 2s - loss: 0.4133 - acc: 0.8299\n",
      "Epoch 98/100\n",
      "3290/7200 [============>.................] - ETA: 2s - loss: 0.4119 - acc: 0.8289\n",
      "4180/7200 [================>.............] - ETA: 1s - loss: 0.4079 - acc: 0.8309Epoch 98/100\n",
      "6460/7200 [=========================>....] - ETA: 0s - loss: 0.4054 - acc: 0.8307\n",
      "Epoch 99/100\n",
      "6190/7200 [========================>.....] - ETA: 0s - loss: 0.4013 - acc: 0.8307\n",
      "3270/7200 [============>.................] - ETA: 3s - loss: 0.4012 - acc: 0.8364Epoch 99/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4014 - acc: 0.8347     \n",
      "Epoch 98/100\n",
      "3870/7200 [===============>..............] - ETA: 2s - loss: 0.4049 - acc: 0.8323\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.3971 - acc: 0.8336     \n",
      "Epoch 99/100\n",
      "4950/7200 [===================>..........] - ETA: 1s - loss: 0.4084 - acc: 0.8317\n",
      "1110/7200 [===>..........................] - ETA: 4s - loss: 0.4216 - acc: 0.8306Epoch 99/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4048 - acc: 0.8342     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 5s - loss: 0.4012 - acc: 0.8342     \n",
      "Epoch 99/100\n",
      "5490/7200 [=====================>........] - ETA: 1s - loss: 0.3939 - acc: 0.8368\n",
      "5170/7200 [====================>.........] - ETA: 1s - loss: 0.4050 - acc: 0.8327Epoch 100/100\n",
      "5340/7200 [=====================>........] - ETA: 1s - loss: 0.4039 - acc: 0.8333\n",
      "5640/7200 [======================>.......] - ETA: 0s - loss: 0.3973 - acc: 0.8353Epoch 100/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4004 - acc: 0.8347     \n",
      "Epoch 100/100\n",
      "6070/7200 [========================>.....] - ETA: 0s - loss: 0.4037 - acc: 0.8336\n",
      " 730/7200 [==>...........................] - ETA: 4s - loss: 0.4194 - acc: 0.8274Epoch 99/100\n",
      "6570/7200 [==========================>...] - ETA: 0s - loss: 0.3980 - acc: 0.8355\n",
      " 980/7200 [===>..........................] - ETA: 3s - loss: 0.4150 - acc: 0.8286Epoch 100/100\n",
      "4990/7200 [===================>..........] - ETA: 1s - loss: 0.3982 - acc: 0.8343\n",
      "Epoch 100/100\n",
      "1150/7200 [===>..........................] - ETA: 3s - loss: 0.3966 - acc: 0.8322\n",
      "5340/7200 [=====================>........] - ETA: 1s - loss: 0.3968 - acc: 0.8348Epoch 100/100\n",
      "7200/7200 [==============================] - 4s - loss: 0.4014 - acc: 0.8343     \n",
      "Epoch 100/100\n",
      "6210/7200 [========================>.....] - ETA: 0s - loss: 0.3980 - acc: 0.8359\n",
      "5520/7200 [======================>.......] - ETA: 1s - loss: 0.4038 - acc: 0.8341\n",
      "7200/7200 [==============================] - 3s - loss: 0.4011 - acc: 0.8357     \n",
      "4440/7200 [=================>............] - ETA: 1s - loss: 0.4054 - acc: 0.8311Epoch 1/100\n",
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4016 - acc: 0.8367     \n",
      "7200/7200 [==============================] - 2s - loss: 0.4868 - acc: 0.7947     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4854 - acc: 0.7944     \n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4298 - acc: 0.7961     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4260 - acc: 0.7957     \n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4251 - acc: 0.7961     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4190 - acc: 0.8092     \n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4219 - acc: 0.8121     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4127 - acc: 0.8326     \n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4198 - acc: 0.8242     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4078 - acc: 0.8339     \n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4181 - acc: 0.8260     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4046 - acc: 0.8372     \n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4166 - acc: 0.8290     \n",
      "7060/7200 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.8360Epoch 8/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4023 - acc: 0.8365     \n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4152 - acc: 0.8294     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4000 - acc: 0.8358     \n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3992 - acc: 0.8371     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4145 - acc: 0.8314     \n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3976 - acc: 0.8360     \n",
      "7200/7200 [==============================] - 2s - loss: 0.4130 - acc: 0.8321     Epoch 11/100\n",
      "\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4117 - acc: 0.8333     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3966 - acc: 0.8379     \n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4113 - acc: 0.8325     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3962 - acc: 0.8356     \n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4102 - acc: 0.8314     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3957 - acc: 0.8361     \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4094 - acc: 0.8322     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3948 - acc: 0.8372     \n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4090 - acc: 0.8339     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3945 - acc: 0.8362     \n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4079 - acc: 0.8328     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3937 - acc: 0.8360     \n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4086 - acc: 0.8325     \n",
      "7000/7200 [============================>.] - ETA: 0s - loss: 0.3934 - acc: 0.8353Epoch 18/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3941 - acc: 0.8350     \n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4078 - acc: 0.8339     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3936 - acc: 0.8360     \n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4074 - acc: 0.8342     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3931 - acc: 0.8390     \n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4072 - acc: 0.8332     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3932 - acc: 0.8357     \n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4072 - acc: 0.8326     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3932 - acc: 0.8356     \n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4066 - acc: 0.8336     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3927 - acc: 0.8365     \n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4061 - acc: 0.8351     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3921 - acc: 0.8358     \n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4063 - acc: 0.8332     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3924 - acc: 0.8379     \n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4059 - acc: 0.8326     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3919 - acc: 0.8357     \n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4059 - acc: 0.8346     \n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3919 - acc: 0.8374     \n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4055 - acc: 0.8331     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3917 - acc: 0.8382     \n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4060 - acc: 0.8332     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3921 - acc: 0.8357     \n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4052 - acc: 0.8333     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3914 - acc: 0.8369     \n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4048 - acc: 0.8336     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3914 - acc: 0.8361     \n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4055 - acc: 0.8328     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3915 - acc: 0.8364     \n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4051 - acc: 0.8333     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3915 - acc: 0.8372     \n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4043 - acc: 0.8340     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3908 - acc: 0.8378     \n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4050 - acc: 0.8332     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3910 - acc: 0.8365     \n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4048 - acc: 0.8337     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3909 - acc: 0.8381     \n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4047 - acc: 0.8329     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3908 - acc: 0.8368     \n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4047 - acc: 0.8324     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3902 - acc: 0.8387     \n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4045 - acc: 0.8349     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3903 - acc: 0.8364     \n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4042 - acc: 0.8344     \n",
      "Epoch 40/100\n",
      " 800/7200 [==>...........................] - ETA: 2s - loss: 0.3655 - acc: 0.8362\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4045 - acc: 0.8325     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3910 - acc: 0.8365     \n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4042 - acc: 0.8336     \n",
      "Epoch 42/100\n",
      " 860/7200 [==>...........................] - ETA: 1s - loss: 0.4320 - acc: 0.8116\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4042 - acc: 0.8349     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3901 - acc: 0.8383     \n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4045 - acc: 0.8331     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3897 - acc: 0.8400     \n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4042 - acc: 0.8337     \n",
      "6390/7200 [=========================>....] - ETA: 0s - loss: 0.3874 - acc: 0.8399Epoch 45/100\n",
      " 810/7200 [==>...........................] - ETA: 2s - loss: 0.4007 - acc: 0.8358\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4040 - acc: 0.8350     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3898 - acc: 0.8376     \n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4040 - acc: 0.8324     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3898 - acc: 0.8378     \n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4038 - acc: 0.8351     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3893 - acc: 0.8399     \n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4039 - acc: 0.8331     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3888 - acc: 0.8389     \n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4042 - acc: 0.8311     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3892 - acc: 0.8399     \n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4040 - acc: 0.8325     \n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3885 - acc: 0.8382     \n",
      "Epoch 51/100\n",
      "6190/7200 [========================>.....] - ETA: 0s - loss: 0.3920 - acc: 0.8384\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3873 - acc: 0.8400     \n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4040 - acc: 0.8347     \n",
      "6150/7200 [========================>.....] - ETA: 0s - loss: 0.3869 - acc: 0.8393Epoch 53/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3870 - acc: 0.8396     \n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4038 - acc: 0.8336     \n",
      "6160/7200 [========================>.....] - ETA: 0s - loss: 0.3841 - acc: 0.8403Epoch 54/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3850 - acc: 0.8397     \n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4036 - acc: 0.8343     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3816 - acc: 0.8383     \n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4040 - acc: 0.8346     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3766 - acc: 0.8400     \n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4037 - acc: 0.8335     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3701 - acc: 0.8450     \n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4036 - acc: 0.8353     \n",
      "6040/7200 [========================>.....] - ETA: 0s - loss: 0.3614 - acc: 0.8493Epoch 58/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3630 - acc: 0.8487     \n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4034 - acc: 0.8340     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3547 - acc: 0.8550     \n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4035 - acc: 0.8342     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3476 - acc: 0.8601     \n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4033 - acc: 0.8344     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3431 - acc: 0.8594     \n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4033 - acc: 0.8353     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3404 - acc: 0.8618     \n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4034 - acc: 0.8336     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3395 - acc: 0.8622     \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4037 - acc: 0.8343     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3393 - acc: 0.8628     \n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4036 - acc: 0.8337     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3388 - acc: 0.8619     \n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4035 - acc: 0.8336     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3383 - acc: 0.8617     \n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4034 - acc: 0.8350     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3377 - acc: 0.8624     \n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4036 - acc: 0.8339     \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3378 - acc: 0.8592     \n",
      "1440/7200 [=====>........................] - ETA: 1s - loss: 0.4035 - acc: 0.8403Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s - loss: 0.4031 - acc: 0.8346     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3374 - acc: 0.8632     \n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4024 - acc: 0.8332     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3365 - acc: 0.8628     \n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4030 - acc: 0.8354     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3366 - acc: 0.8604     \n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4029 - acc: 0.8343     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3363 - acc: 0.8625     \n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4036 - acc: 0.8354     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3365 - acc: 0.8621     \n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4030 - acc: 0.8336     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3365 - acc: 0.8610     \n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4036 - acc: 0.8335     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3360 - acc: 0.8622     \n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4033 - acc: 0.8331     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3359 - acc: 0.8617     \n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4037 - acc: 0.8349     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3367 - acc: 0.8622     \n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4030 - acc: 0.8315     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3358 - acc: 0.8608     \n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4034 - acc: 0.8344     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3353 - acc: 0.8619     \n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4030 - acc: 0.8347     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3355 - acc: 0.8631     \n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4029 - acc: 0.8319     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3354 - acc: 0.8611     \n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4029 - acc: 0.8333     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3359 - acc: 0.8635     \n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4032 - acc: 0.8344     \n",
      "5580/7200 [======================>.......] - ETA: 0s - loss: 0.3399 - acc: 0.8581Epoch 83/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3354 - acc: 0.8608     \n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4027 - acc: 0.8357     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3347 - acc: 0.8608     \n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4033 - acc: 0.8333     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3356 - acc: 0.8622     \n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4029 - acc: 0.8358     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3348 - acc: 0.8612     \n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4034 - acc: 0.8331     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3353 - acc: 0.8608     \n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4026 - acc: 0.8331     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3351 - acc: 0.8622     \n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4034 - acc: 0.8335     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3352 - acc: 0.8625     \n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4028 - acc: 0.8333     \n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3347 - acc: 0.8621     \n",
      "1760/7200 [======>.......................] - ETA: 1s - loss: 0.4126 - acc: 0.8267Epoch 90/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4031 - acc: 0.8336     \n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3351 - acc: 0.8636     \n",
      "Epoch 91/100\n",
      "5420/7200 [=====================>........] - ETA: 0s - loss: 0.3367 - acc: 0.8587\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3348 - acc: 0.8607     \n",
      "1780/7200 [======>.......................] - ETA: 1s - loss: 0.4008 - acc: 0.8326Epoch 92/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4028 - acc: 0.8332     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3341 - acc: 0.8636     \n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4028 - acc: 0.8324     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3348 - acc: 0.8642     \n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4027 - acc: 0.8347     \n",
      "Epoch 95/100\n",
      "1790/7200 [======>.......................] - ETA: 1s - loss: 0.4012 - acc: 0.8341\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4024 - acc: 0.8337     \n",
      "5420/7200 [=====================>........] - ETA: 0s - loss: 0.3344 - acc: 0.8638Epoch 96/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3344 - acc: 0.8632     \n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4029 - acc: 0.8342     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3344 - acc: 0.8618     \n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4032 - acc: 0.8339     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3346 - acc: 0.8621     \n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4023 - acc: 0.8340     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3343 - acc: 0.8642     \n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4032 - acc: 0.8339     \n",
      "5390/7200 [=====================>........] - ETA: 0s - loss: 0.3309 - acc: 0.8644Epoch 100/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.3346 - acc: 0.8643     \n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 2s - loss: 0.4027 - acc: 0.8326     \n",
      "7200/7200 [==============================] - 2s - loss: 0.3340 - acc: 0.8612     \n",
      "790/800 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#Contains the accuracies for each fold\n",
    "#n-jobs = number of cpus to use \n",
    "#n-jobs = -1 - all cpus - parallel\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83999999,  0.83999999,  0.83375   ,  0.83      ,  0.84874999,\n",
       "        0.84      ,  0.83      ,  0.8175    ,  0.84124999,  0.8525    ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83737499501556167"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = accuracies.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0095434852860238947"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = accuracies.std()\n",
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Regularization\n",
    "\n",
    "Used to avoid overfitting - large variance in accuracy between training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "/Users/aoife.whelan/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4898 - acc: 0.7960     \n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4339 - acc: 0.7960     \n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4317 - acc: 0.7960     \n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4329 - acc: 0.7960     \n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4307 - acc: 0.7960     \n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4287 - acc: 0.8006     \n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4264 - acc: 0.8197     \n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4279 - acc: 0.8230     \n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4267 - acc: 0.8230     \n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4257 - acc: 0.8241     \n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4247 - acc: 0.8254     \n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4266 - acc: 0.8266     \n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4235 - acc: 0.8272     \n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4263 - acc: 0.8280     \n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4280 - acc: 0.8260     \n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4254 - acc: 0.8276     \n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4234 - acc: 0.8284     \n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4245 - acc: 0.8264     \n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4251 - acc: 0.8275     \n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4215 - acc: 0.8291     \n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4236 - acc: 0.8307     \n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4247 - acc: 0.8300     \n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4219 - acc: 0.8274     \n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4231 - acc: 0.8297     \n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4250 - acc: 0.8286     \n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4243 - acc: 0.8279     \n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4246 - acc: 0.8275     \n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4251 - acc: 0.8274     \n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4202 - acc: 0.8310     \n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4216 - acc: 0.8269     \n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4205 - acc: 0.8295     \n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4203 - acc: 0.8280     \n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4212 - acc: 0.8310     \n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4243 - acc: 0.8279     \n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4242 - acc: 0.8289     \n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4219 - acc: 0.8315     \n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4217 - acc: 0.8297     \n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4213 - acc: 0.8305     \n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4242 - acc: 0.8311     \n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4209 - acc: 0.8291     \n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4263 - acc: 0.8299     \n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4203 - acc: 0.8291     \n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4230 - acc: 0.8299     \n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4210 - acc: 0.8286     \n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4192 - acc: 0.8302     \n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4242 - acc: 0.8282     \n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4255 - acc: 0.8305     \n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4232 - acc: 0.8300     \n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4224 - acc: 0.8314     \n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4239 - acc: 0.8297     \n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4227 - acc: 0.8317     \n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4231 - acc: 0.8327     \n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4237 - acc: 0.8312     \n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4246 - acc: 0.8304     \n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4231 - acc: 0.8297     \n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4226 - acc: 0.8317     \n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4245 - acc: 0.8304     \n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4198 - acc: 0.8337     \n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4223 - acc: 0.8310     \n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4214 - acc: 0.8299     \n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4209 - acc: 0.8330     \n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4241 - acc: 0.8284     \n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4238 - acc: 0.8277     \n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4207 - acc: 0.8329     \n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4226 - acc: 0.8299     \n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4202 - acc: 0.8279     \n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4205 - acc: 0.8326     \n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4221 - acc: 0.8291     \n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4209 - acc: 0.8304     \n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4224 - acc: 0.8307     \n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4211 - acc: 0.8295     \n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4201 - acc: 0.8296     \n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4200 - acc: 0.8301     \n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4202 - acc: 0.8325     \n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4210 - acc: 0.8315     \n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4236 - acc: 0.8305     \n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4185 - acc: 0.8312     \n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4218 - acc: 0.8316     \n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4244 - acc: 0.8309     \n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4217 - acc: 0.8316     \n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4248 - acc: 0.8331     \n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4240 - acc: 0.8297     \n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4226 - acc: 0.8292     \n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4219 - acc: 0.8315     \n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4236 - acc: 0.8300     \n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4202 - acc: 0.8319     \n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 2s - loss: 0.4182 - acc: 0.8302     \n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4195 - acc: 0.8315     \n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4218 - acc: 0.8317     \n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4198 - acc: 0.8311     \n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4247 - acc: 0.8300     \n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4221 - acc: 0.8292     \n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4214 - acc: 0.8304     \n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4201 - acc: 0.8311     \n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4234 - acc: 0.8327     \n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4232 - acc: 0.8295     \n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4219 - acc: 0.8306     \n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4229 - acc: 0.8314     \n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4204 - acc: 0.8302     \n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 2s - loss: 0.4220 - acc: 0.8307     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a16aca9e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "classifier.add(Dropout(rate = 0.1)) #increase rate as you try to correct overfitting\n",
    "#do not go past 0.5 to reduce risk of underfitting\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As before but without batchsize/epoch number\n",
    "classifier = KerasClassifier(build_fn = build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary of hyperparameters to test\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs': [100, 500],\n",
    "              'optimizer': ['adam', 'rmsprop']} #rmsprop recommended for RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit to training set - several hours\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turorial result - batch = 25, epoch = 500m, optimizer = rmsprop\n",
    "best_parameters = grid_search.best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial result - 0.85\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "Put me one step down on the podium by getting this 86% accuracy with k-Fold Cross Validation.\n",
    "\n",
    "As a reminder:\n",
    "\n",
    "Bronze medal: Accuracy between 84% and 85%\n",
    "\n",
    "Silver medal: Accuracy between 85% and 86%\n",
    "\n",
    "Gold medal: Accuracy over 86%\n",
    "\n",
    "Good luck on getting the gold medal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
